import os # dosya yollarÄ±nÄ± yÃ¶netmek
from dotenv import load_dotenv # .env dosyasÄ±ndan Ã§evresel deÄŸiÅŸkenleri yÃ¼klemek
import openai # OpenAI API (ya da openrouter) ile etkileÅŸim iÃ§in
import fitz  # PyMuPDF, pdf dosyalarÄ±nÄ± okumak iÃ§in


def load_pdf_chunks(pdf_path: str) -> list:
    """PDF'yi yÃ¼kler ve sayfa baÅŸÄ±na metin parÃ§alarÄ±na bÃ¶ler."""
    doc = fitz.open(pdf_path)
    chunks = []
    for page in doc:
        text = page.get_text().strip()
        if text:
            chunks.append(text)
    return chunks

def find_best_chunk(question: str, chunks: list) -> str:
    """Anahtar kelime Ã¶rtÃ¼ÅŸmesi en fazla olan parÃ§ayÄ± seÃ§ip LLM'e gÃ¶nderir."""
    question_words = set(question.lower().split())
    best_chunk = ""
    max_matches = -1
    for chunk in chunks:
        words = set(chunk.lower().split())
        matches = len(question_words & words)
        if matches > max_matches:
            max_matches = matches
            best_chunk = chunk
    return best_chunk


def ask_llm(chunk: str, question: str) -> str:
    """SeÃ§ilen parÃ§ayÄ± ve soruyu OpenRouter Ã¼zerinden LLM'e gÃ¶nderir, cevabÄ±nÄ± alÄ±r."""
    load_dotenv()
    api_key = os.getenv("OPENROUTER_API_KEY")
    client = openai.OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

    prompt = f"Belgeden AlÄ±ntÄ±:\n{chunk}\n\nSoru: {question}\nCevap:"
    response = client.chat.completions.create(
        model="openai/gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()


if __name__ == "__main__":
    """Ana program akÄ±ÅŸÄ±."""
    print("ğŸ“„ PDF iÃ§eriÄŸini sorgulama arayÃ¼zÃ¼ne hoÅŸ geldiniz.\n")
    base_path = os.path.dirname(__file__)
    pdf_path = os.path.join(base_path, input("PDF dosyasÄ±nÄ±n yolu nedir? (bu denemede: assets/cihad-icin-on-hadis.pdf): ").strip())


    try:
        chunks = load_pdf_chunks(pdf_path)
    except Exception as e:
        print("âŒ PDF yÃ¼klenemedi:", e)
        raise SystemExit

    if not chunks:
        print("âš ï¸ PDF iÃ§eriÄŸi boÅŸ bulundu.")
        raise SystemExit
    
    question = input("Belgeden Ã¶ÄŸrenmek istediÄŸiniz nedir?: ").strip()
    best_chunk = find_best_chunk(question, chunks)
    answer = ask_llm(best_chunk, question)

    print("\nğŸ“Œ Cevap:\n", answer)