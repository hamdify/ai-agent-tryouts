# ğŸ“š Multi-Doc RAG â€“ Ã‡oklu Belgelerden AkÄ±llÄ± Cevaplama

Bu klasÃ¶rde, uzun metinler (>10 sayfa) veya birden fazla belgeyi iÅŸleyerek RAG (Retrieval-Augmented Generation) mimarisiyle akÄ±llÄ± cevaplama yapÄ±yoruz.

## ğŸ“Œ Konsept:
- Ã‡oklu metin veya uzun PDF dosyalarÄ± chunk'lara bÃ¶lÃ¼nÃ¼r
- Her chunk `embedding` ile vektÃ¶r formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
- KullanÄ±cÄ±dan gelen soru embed edilir ve vektÃ¶r veritabanÄ±nda en benzer parÃ§a seÃ§ilir
- SeÃ§ilen iÃ§erik + soru birlikte LLM'e gÃ¶nderilerek cevap Ã¼retilir

## ğŸ¯ AmaÃ§:
- GerÃ§ek dÃ¼nya belgelerinden akÄ±llÄ± bilgi Ã§Ä±karÄ±mÄ±
- RAG yapÄ±sÄ±nÄ±n uÃ§tan uca uygulanmasÄ±
- Belge tabanlÄ± agent sistemlerinin temelini kurmak

## ğŸ§  KullanÄ±lan Teknolojiler:
- FAISS veya ChromaDB (vector database)
- OpenAI / OpenRouter Embedding API
- `text-embedding-ada-002` veya `nomic-embed-text-v1`
- PDF & metin parsing, chunking, filtering

## ğŸ” Ã–rnek Uygulama:
- Belgeler: `project_summary.pdf`, `team_report.md`, `faq.txt`
- Soru: â€œÅirketin 2024 sÃ¼rdÃ¼rÃ¼lebilirlik hedefleri nelerdir?â€
- Cevap: En uygun chunk bulunur â†’ LLM'e baÄŸlam verilir â†’ akÄ±llÄ± yanÄ±t dÃ¶ner

---

## âš ï¸ Not:
- Chunk boyutu, arama vektÃ¶rÃ¼ kalitesi ve LLM modeli cevabÄ±n doÄŸruluÄŸunu doÄŸrudan etkiler.